{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import csv\n",
    "import sys\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../speeches\"\n",
    "RESULTS_DIR = \"../speeches/results\"\n",
    "CSV_DIR = RESULTS_DIR + \"/csvs\"\n",
    "PICKLES_DIR = RESULTS_DIR + \"/pickles\"\n",
    "SPEECHES_DIR = DATA_DIR + \"/transcripts_english\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "os.makedirs(PICKLES_DIR, exist_ok=True)\n",
    "os.makedirs(SPEECHES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"remove_words.txt\", \"r\") as f:\n",
    "    MORE_STOPWORDS = f.read().split(\"\\n\")\n",
    "\n",
    "STOPWORDS = stopwords.words('english')\n",
    "WC_STOP = set(list(STOPWORDS) + MORE_STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "dates = []\n",
    "speeches = []\n",
    "\n",
    "with open(DATA_DIR + \"/mann_ki_baat.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"|\")\n",
    "    for row in reader:\n",
    "        urls.append(row[0])\n",
    "        dates.append(row[1])\n",
    "        speeches.append(row[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write each speech into txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "month_to_num = {}\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "for month in months:\n",
    "    if i < 10:\n",
    "        month_to_num[month] = \"0\" + str(i)\n",
    "    else:\n",
    "        month_to_num[month] = str(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"/mann_ki_baat.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"|\")\n",
    "    for row in reader:\n",
    "        date = row[1].split(',')[1].strip() + \"_\" + month_to_num[row[1].split(' ')[1].strip(',')] + \"_\" + row[1].split(' ')[0]\n",
    "        with open(SPEECHES_DIR+f\"/{date}.txt\", \"w\") as f:\n",
    "            f.write(row[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nums(text):\n",
    "    return re.sub(\"\\d\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_row(row):\n",
    "    content = remove_nums(row[2])\n",
    "    lemmatized_content = \"\"\n",
    "    for word in content:\n",
    "        lemmatized_content += lemmatizer.lemmatize(word)\n",
    "    row[2] =  lemmatized_content\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    # Convert to lower case\n",
    "    data = data.lower()\n",
    "    # Make a look-up for punctuations\n",
    "    punctuation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    # remove punctuations, multiple consecutive spaces\n",
    "    data = re.sub(\" +\", \" \", data.translate(punctuation_table))\n",
    "    # split into words\n",
    "    words = word_tokenize(data)\n",
    "    # remove stopwords\n",
    "    cleaned_words = [word for word in words if word not in STOPWORDS]\n",
    "    return \" \".join(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 11 ms, total: 1.82 s\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cleaned_speeches = [clean(speech) for speech in speeches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-transcript-of-the-special-episode-of-mann-ki-baat-pm-shri-narendra-modi-and-us-president-shri-barack-obama-share-their-thoughts-on-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-the-text-of-pms-first-address-to-the-nation-on-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-text-of-prime-ministers-mann-ki-baat-on-all-india-radio-on-26th-april-2015/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-text-of-prime-ministers-mann-ki-baat-on-all-india-radio-in-february-2015/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-pms-mann-ki-baat-address-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-text-of-prime-ministers-mann-ki-baat-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-text-of-pms-mann-ki-baat-on-all-india-radio-on-27-12-2015/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-text-of-prime-ministers-mann-ki-baat-on-all-india-radio-on-20th-september-2015/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-prime-ministers-mann-ki-baat-on-all-india-radio-29th-november-2015/\n",
      "https://www.pmindia.gov.in/en/news_updates/text-of-prime-ministers-mann-ki-baat-on-all-india-radio-9/\n",
      "https://www.pmindia.gov.in/en/news_updates/text-of-prime-ministers-mann-ki-baat-on-all-india-radio-8/\n",
      "https://www.pmindia.gov.in/en/news_updates/text-of-pms-mann-ki-baat-programme-on-all-india-radio-2/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-pms-mann-ki-baat-on-all-india-radio-on-october-2015/\n",
      "https://www.pmindia.gov.in/en/news_updates/text-of-pms-mann-ki-baatprogramme-on-all-india-radio-on-22-05-2016/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-on-june-26-2016/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-on-august-28-2016/\n",
      "https://www.pmindia.gov.in/en/news_updates/text-of-pms-mann-ki-baat-programme-on-all-india-radio-on-25-september-2016/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-address-on-all-india-radio-on-30-october-2016/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-address-on-all-india-radio-2/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-address-on-all-india-radio-3/\n",
      "https://www.pmindia.gov.in/en/news_updates/text-of-pms-mann-ki-baat-programme-on-all-india-radio-3/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-mann-ki-baat-address-by-pm-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-3/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-4/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-5/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-6/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-7/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-9/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-10/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-11/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-12/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-13/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-the-text-of-prime-minister-shri-narendra-modis-address-to-the-nation-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-the-text-of-prime-ministers-mann-ki-baat-on-all-india-radio-on-14th-december-2014/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-prime-ministers-mann-ki-baat-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-15/\n",
      "https://www.pmindia.gov.in/en/news_updates/english-rendering-of-pms-mann-ki-baat-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-18/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-48th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-19/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-17/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-21/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-address-on-all-india-radio/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-2nd-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-3rd-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-4th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-address-on-all-india-radio-4/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-5th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-6th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-7th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-8th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-9th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-11th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-10th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-12th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-13th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-14th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-15th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-17th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-16th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-2/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-18th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-19th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-20th-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-21st-episode-of-mann-ki-baat-2-0/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-75thepisode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-76th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-79th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-77th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-78th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-80th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-82nd-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-81st-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-84th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-83rd-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-85th-episode-of-mann-ki-baat-on-30-01-2022/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-87th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-the-86th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-14/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-16/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-mann-ki-baat-programme-on-all-india-radio-20/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-50th-episode-of-mann-ki-baat/\n",
      "https://www.pmindia.gov.in/en/news_updates/pms-address-in-mann-ki-baat-2-0programme-on-all-india-radio/\n"
     ]
    }
   ],
   "source": [
    "with open(CSV_DIR+\"/cleaned_mann_ki_baat.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=\"|\", quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(len(urls)):\n",
    "        print(urls[i])\n",
    "        writer.writerow([urls[i], dates[i], cleaned_speeches[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Pickle File for easier loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv = []\n",
    "mann_ki_baat = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CSV_DIR + \"/cleaned_mann_ki_baat.csv\", \"r\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"|\")\n",
    "    for row in reader:\n",
    "        lemmatized_row = lemmatize_row(row)\n",
    "        new_csv.append(lemmatized_row)\n",
    "        month = str(row[1].split(',')[0].split(' ')[1] + row[1].split(',')[1])\n",
    "        if month not in mann_ki_baat:\n",
    "            mann_ki_baat[month] = []\n",
    "            mann_ki_baat[month].append({\"url\": row[0], \"date\": row[1], \"speech\": row[2]})\n",
    "        else:\n",
    "            mann_ki_baat[month].append({\"url\": row[0], \"date\": row[1], \"speech\": row[2]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "dict_keys(['Jan 2015', 'Oct 2014', 'Apr 2015', 'Feb 2015', 'Mar 2015', 'Nov 2014', 'Dec 2015', 'Sep 2015', 'Nov 2015', 'Feb 2016', 'Jan 2016', 'Mar 2016', 'Oct 2015', 'May 2016', 'Jun 2016', 'Jul 2016', 'Aug 2016', 'Sep 2016', 'Oct 2016', 'Dec 2016', 'Jan 2017', 'Mar 2017', 'Apr 2017', 'Jun 2017', 'Jul 2017', 'Aug 2017', 'Sep 2017', 'Oct 2017', 'Dec 2017', 'Jan 2018', 'Feb 2018', 'Mar 2018', 'Apr 2018', 'May 2015', 'Dec 2014', 'Jul 2015', 'Jun 2018', 'Aug 2015', 'Oct 2018', 'Sep 2018', 'Dec 2018', 'Aug 2018', 'Feb 2019', 'Nov 2016', 'Jul 2019', 'Aug 2019', 'Sep 2019', 'Feb 2017', 'Oct 2019', 'Nov 2019', 'Dec 2019', 'Jan 2020', 'Feb 2020', 'Apr 2020', 'Mar 2020', 'May 2020', 'Jun 2020', 'Jul 2020', 'Aug 2020', 'Oct 2020', 'Sep 2020', 'May 2017', 'Nov 2020', 'Dec 2020', 'Jan 2021', 'Feb 2021', 'Mar 2021', 'Apr 2021', 'Jul 2021', 'May 2021', 'Jun 2021', 'Aug 2021', 'Oct 2021', 'Sep 2021', 'Dec 2021', 'Nov 2021', 'Jan 2022', 'Mar 2022', 'Feb 2022', 'May 2018', 'Jul 2018', 'Jan 2019', 'Nov 2018', 'Jun 2019'])\n"
     ]
    }
   ],
   "source": [
    "print(len(list(mann_ki_baat.keys())))\n",
    "print(mann_ki_baat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CSV_DIR+\"/lemmatized_mann_ki_baat.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=\"|\", quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(len(new_csv)):\n",
    "        writer.writerow(new_csv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLES_DIR+\"/mann_ki_baat.pkl\", \"wb\") as f:\n",
    "    cPickle.dump(mann_ki_baat, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data by Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonetisation ; starting date: 8 November 2016\n",
    "\n",
    "demonetisation_collection = {}\n",
    "demonetisation_months = ['Nov 2016', 'Dec 2016', 'Jan 2017', 'Feb 2017', 'Mar 2017']\n",
    "\n",
    "for month in demonetisation_months:\n",
    "    if month not in demonetisation_collection:\n",
    "            demonetisation_collections = ''\n",
    "            demonetisation_collections += mann_ki_baat[month][0]['speech']\n",
    "\n",
    "demonetisation_collection['demonetisation'] = demonetisation_collections\n",
    "\n",
    "with open(PICKLES_DIR+\"/mann_ki_baat_demonetisation.pkl\", \"wb\") as f:\n",
    "    cPickle.dump(demonetisation_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caa_nrc ; starting date:\n",
    "\n",
    "caa_nrc_collection = {}\n",
    "caa_nrc_months = ['Dec 2019', 'Jan 2020', 'Feb 2020', 'Mar 2020', 'Apr 2020']\n",
    "\n",
    "for month in caa_nrc_months:\n",
    "    if month not in caa_nrc_collection:\n",
    "            caa_nrc_collections = ''\n",
    "            caa_nrc_collections += mann_ki_baat[month][0]['speech']\n",
    "\n",
    "caa_nrc_collection['caa_nrc'] = caa_nrc_collections\n",
    "\n",
    "with open(PICKLES_DIR+\"/mann_ki_baat_caa_nrc.pkl\", \"wb\") as f:\n",
    "    cPickle.dump(caa_nrc_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# farmers ; starting date: \n",
    "\n",
    "farmers_collection = {}\n",
    "farmers_months = ['Aug 2020', 'Sep 2020', 'Oct 2020', 'Nov 2020', 'Dec 2020', 'Jan 2021', 'Feb 2021', 'Mar 2021', 'Apr 2021', 'May 2021', 'Jun 2021', 'Jul 2021', 'Aug 2021', 'Sep 2021', 'Oct 2021', 'Nov 2021']\n",
    "\n",
    "for month in farmers_months:\n",
    "    if month not in farmers_collection:\n",
    "            farmers_collections = ''\n",
    "            farmers_collections += mann_ki_baat[month][0]['speech']\n",
    "\n",
    "farmers_collection['farmers'] = farmers_collections\n",
    "\n",
    "with open(PICKLES_DIR+\"/mann_ki_baat_farmers.pkl\", \"wb\") as f:\n",
    "    cPickle.dump(farmers_collection, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check frequency of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR_2 = RESULTS_DIR + \"/frequencies\"\n",
    "RESULTS_DIR_3 = RESULTS_DIR_2 + \"/demonetisation\"\n",
    "RESULTS_DIR_4 = RESULTS_DIR_2 + \"/caa_nrc\"\n",
    "RESULTS_DIR_5 = RESULTS_DIR_2 + \"/farmers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 0 ns, total: 158 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs(RESULTS_DIR_2, exist_ok=True)\n",
    "NUM_COUNTS = 500\n",
    "\n",
    "with open(PICKLES_DIR + \"/mann_ki_baat.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)\n",
    "\n",
    "whole_word_freq = Counter()\n",
    "for k in content.keys():\n",
    "    word_freq = Counter()\n",
    "    for word in content[k][0]['speech'].split(\" \"):\n",
    "        if word not in WC_STOP:\n",
    "            word_freq[word] += 1\n",
    "            whole_word_freq[word] += 1\n",
    "    common_words = word_freq.most_common(NUM_COUNTS)\n",
    "    with open(RESULTS_DIR_2 + f\"/{k}.txt\", \"w\") as f:\n",
    "        for word_count in common_words:\n",
    "            f.write(f\"{word_count[0]} : {word_count[1]}\\n\")\n",
    "\n",
    "common_words = whole_word_freq.most_common(NUM_COUNTS)\n",
    "with open(RESULTS_DIR_2 + \"/All.txt\", \"w\") as f:\n",
    "    for word_count in common_words:\n",
    "        f.write(f\"{word_count[0]} : {word_count[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.57 ms, sys: 0 ns, total: 5.57 ms\n",
      "Wall time: 5.07 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs(RESULTS_DIR_3, exist_ok=True)\n",
    "NUM_COUNTS = 500\n",
    "\n",
    "with open(PICKLES_DIR + \"/mann_ki_baat_demonetisation.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)\n",
    "\n",
    "whole_word_freq = Counter()\n",
    "for k in content.keys():\n",
    "    word_freq = Counter()\n",
    "    for word in content[k].split(\" \"):\n",
    "        if word not in WC_STOP:\n",
    "            word_freq[word] += 1\n",
    "            whole_word_freq[word] += 1\n",
    "    common_words = word_freq.most_common(NUM_COUNTS)\n",
    "    with open(RESULTS_DIR_3 + f\"/{k}.txt\", \"w\") as f:\n",
    "        for word_count in common_words:\n",
    "            f.write(f\"{word_count[0]} : {word_count[1]}\\n\")\n",
    "\n",
    "common_words = whole_word_freq.most_common(NUM_COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.89 ms, sys: 0 ns, total: 4.89 ms\n",
      "Wall time: 3.93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs(RESULTS_DIR_4, exist_ok=True)\n",
    "NUM_COUNTS = 500\n",
    "\n",
    "with open(PICKLES_DIR + \"/mann_ki_baat_caa_nrc.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)\n",
    "\n",
    "whole_word_freq = Counter()\n",
    "for k in content.keys():\n",
    "    word_freq = Counter()\n",
    "    for word in content[k].split(\" \"):\n",
    "        if word not in WC_STOP:\n",
    "            word_freq[word] += 1\n",
    "            whole_word_freq[word] += 1\n",
    "    common_words = word_freq.most_common(NUM_COUNTS)\n",
    "    with open(RESULTS_DIR_4 + f\"/{k}.txt\", \"w\") as f:\n",
    "        for word_count in common_words:\n",
    "            f.write(f\"{word_count[0]} : {word_count[1]}\\n\")\n",
    "\n",
    "common_words = whole_word_freq.most_common(NUM_COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.39 ms, sys: 0 ns, total: 5.39 ms\n",
      "Wall time: 4.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs(RESULTS_DIR_5, exist_ok=True)\n",
    "NUM_COUNTS = 500\n",
    "\n",
    "with open(PICKLES_DIR + \"/mann_ki_baat_farmers.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)\n",
    "\n",
    "whole_word_freq = Counter()\n",
    "for k in content.keys():\n",
    "    word_freq = Counter()\n",
    "    for word in content[k].split(\" \"):\n",
    "        if word not in WC_STOP:\n",
    "            word_freq[word] += 1\n",
    "            whole_word_freq[word] += 1\n",
    "    common_words = word_freq.most_common(NUM_COUNTS)\n",
    "    with open(RESULTS_DIR_5 + f\"/{k}.txt\", \"w\") as f:\n",
    "        for word_count in common_words:\n",
    "            f.write(f\"{word_count[0]} : {word_count[1]}\\n\")\n",
    "\n",
    "common_words = whole_word_freq.most_common(NUM_COUNTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLES_DIR + \"/mann_ki_baat.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_content = []\n",
    "content_string = ''\n",
    "for month in content.keys():\n",
    "    total_content.append(content[k][0]['speech'])\n",
    "    content_string += content[k][0]['speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,speech in enumerate(total_content):\n",
    "    with open(RESULTS_DIR + \"/full_speeches.txt\", \"a\") as f:\n",
    "        f.write(\"**********\\n\" + total_content[i] + \"**********\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = WordCloud(stopwords=WC_STOP).process_text(content_string)\n",
    "wordcloud = WordCloud(stopwords=WC_STOP, max_words=100).generate(content_string)\n",
    "wdcldsvg = wordcloud.to_svg()\n",
    "with open(RESULTS_DIR +\"/wordclouds/ALL.svg\", \"w\") as f:\n",
    "    f.write(wdcldsvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, text in mann_ki_baat.items():\n",
    "    wordcloud = WordCloud(stopwords=WC_STOP).generate(text[0]['speech'])\n",
    "    wdcldsvg = wordcloud.to_svg()\n",
    "    with open(RESULTS_DIR + f\"/wordclouds/each_speech/{month}.svg\", \"w\") as f:\n",
    "        f.write(wdcldsvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_extra = ['people', 'india', 'world', 'dear', 'country']\n",
    "WC_STOP = WC_STOP | set(stopwords_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLES_DIR + \"/mann_ki_baat_demonetisation.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)\n",
    "\n",
    "content_string = ''\n",
    "for month in content.keys():\n",
    "    content_string += content[month]\n",
    "\n",
    "freq_words = WordCloud(stopwords=WC_STOP).process_text(content_string)\n",
    "wordcloud = WordCloud(stopwords=WC_STOP, max_words=100).generate(content_string)\n",
    "wdcldsvg = wordcloud.to_svg()\n",
    "with open(RESULTS_DIR +\"/wordclouds/demonetisation.svg\", \"w\") as f:\n",
    "    f.write(wdcldsvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLES_DIR + \"/mann_ki_baat_caa_nrc.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)\n",
    "\n",
    "content_string = ''\n",
    "for month in content.keys():\n",
    "    content_string += content[month]\n",
    "\n",
    "freq_words = WordCloud(stopwords=WC_STOP).process_text(content_string)\n",
    "wordcloud = WordCloud(stopwords=WC_STOP, max_words=100).generate(content_string)\n",
    "wdcldsvg = wordcloud.to_svg()\n",
    "with open(RESULTS_DIR +\"/wordclouds/caa_nrc.svg\", \"w\") as f:\n",
    "    f.write(wdcldsvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLES_DIR + \"/mann_ki_baat_farmers.pkl\", \"rb\") as f:\n",
    "    content = cPickle.load(f)\n",
    "\n",
    "content_string = ''\n",
    "for month in content.keys():\n",
    "    content_string += content[month]\n",
    "\n",
    "freq_words = WordCloud(stopwords=WC_STOP).process_text(content_string)\n",
    "wordcloud = WordCloud(stopwords=WC_STOP, max_words=100).generate(content_string)\n",
    "wdcldsvg = wordcloud.to_svg()\n",
    "with open(RESULTS_DIR +\"/wordclouds/farmers.svg\", \"w\") as f:\n",
    "    f.write(wdcldsvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "069fd38f6cc964e80aa64be22201a6a61411afc451904091a31ae1fa4b17e129"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
